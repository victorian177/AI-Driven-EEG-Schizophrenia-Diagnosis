{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generisAPI.featuresExtraction' from 'c:\\\\Users\\\\Victor Momodu\\\\Documents\\\\Programming\\\\Machine Learning\\\\Code\\\\AI-Driven-EEG-Schizophrenia-Diagnosis\\\\notebooks\\\\generisAPI\\\\featuresExtraction.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyedflib import EdfReader\n",
    "import mne\n",
    "import EntropyHub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.interpolate import PchipInterpolator, interp1d\n",
    "\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "import generisAPI\n",
    "\n",
    "importlib.reload(generisAPI)\n",
    "\n",
    "import generisAPI.file_operators as fp\n",
    "\n",
    "importlib.reload(generisAPI.file_operators)\n",
    "\n",
    "import generisAPI.data_cleaning as dcln\n",
    "\n",
    "importlib.reload(generisAPI.data_cleaning)\n",
    "\n",
    "import generisAPI.preprocessing as ppcn\n",
    "\n",
    "importlib.reload(generisAPI.preprocessing)\n",
    "\n",
    "import generisAPI.processing as pcn\n",
    "\n",
    "importlib.reload(generisAPI.processing)\n",
    "\n",
    "import generisAPI.audProcessing as audpcn\n",
    "\n",
    "importlib.reload(generisAPI.audProcessing)\n",
    "\n",
    "import generisAPI.plots as plots\n",
    "\n",
    "importlib.reload(generisAPI.plots)\n",
    "\n",
    "import generisAPI.fuzzEntropy as fuzzEnt\n",
    "\n",
    "importlib.reload(generisAPI.fuzzEntropy)\n",
    "\n",
    "import generisAPI.featuresExtraction as features\n",
    "\n",
    "importlib.reload(generisAPI.featuresExtraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import, compile data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definitions\n",
    "electrodes = [\n",
    "    \"Fp1\",\n",
    "    \"Fp2\",\n",
    "    \"F3\",\n",
    "    \"F4\",\n",
    "    \"C3\",\n",
    "    \"C4\",\n",
    "    \"P3\",\n",
    "    \"P4\",\n",
    "    \"O1\",\n",
    "    \"O2\",\n",
    "    \"F7\",\n",
    "    \"F8\",\n",
    "    \"T3\",\n",
    "    \"T4\",\n",
    "    \"T5\",\n",
    "    \"T6\",\n",
    "    \"Fz\",\n",
    "    \"Pz\",\n",
    "    \"Cz\",\n",
    "]\n",
    "len(electrodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# compile eeg_data and annotations\n",
    "subjects_dataset_root_path = \"../acquired_dataset/\"\n",
    "\n",
    "data = fp.xtract_id_subject_info_dict(subjects_dataset_root_path)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(0, 0, 0), dtype=float64),\n",
       " array([[-325.        , -325.        , -325.        , ..., -138.33333333,\n",
       "         -135.        , -135.        ],\n",
       "        [-325.        , -325.        , -325.        , ..., -199.28571429,\n",
       "          -91.82539683,  -91.82539683],\n",
       "        [-325.        , -325.        , -325.        , ..., -216.74603175,\n",
       "         -160.87301587, -160.87301587],\n",
       "        ...,\n",
       "        [   8.33333333,    8.33333333,   21.98412698, ...,   12.77777778,\n",
       "           -6.11111111,   -6.11111111],\n",
       "        [ -23.25396825,  -23.25396825,   -6.9047619 , ...,   23.25396825,\n",
       "           -1.50793651,   -1.50793651],\n",
       "        [-166.26984127, -166.26984127, -166.26984127, ..., -321.82539683,\n",
       "         -321.82539683, -321.82539683]]),\n",
       " array([[   3.88888889,    3.88888889, -170.3968254 , ...,  126.9047619 ,\n",
       "           17.38095238,   17.38095238],\n",
       "        [-253.88888889, -253.88888889, -147.6984127 , ...,   93.0952381 ,\n",
       "            9.12698413,    9.12698413],\n",
       "        [   4.36507937,    4.36507937, -155.95238095, ...,  100.55555556,\n",
       "           -4.04761905,   -4.04761905],\n",
       "        ...,\n",
       "        [-157.6984127 , -157.6984127 ,  159.6031746 , ...,  -79.28571429,\n",
       "           97.6984127 ,   97.6984127 ],\n",
       "        [-118.80952381, -118.80952381,  124.52380952, ...,  -68.49206349,\n",
       "           71.98412698,   71.98412698],\n",
       "        [-166.26984127, -166.26984127, -166.26984127, ..., -321.82539683,\n",
       "         -321.82539683, -321.82539683]]),\n",
       " array([[-241.19047619, -241.19047619, -325.        , ...,   -5.15873016,\n",
       "          -47.53968254,  -47.53968254],\n",
       "        [-238.96825397, -238.96825397,   59.12698413, ...,  -10.3968254 ,\n",
       "          -34.36507937,  -34.36507937],\n",
       "        [-244.52380952, -244.52380952, -325.        , ...,   -7.53968254,\n",
       "          -17.53968254,  -17.53968254],\n",
       "        ...,\n",
       "        [ -36.74603175,  -36.74603175,   40.07936508, ...,    4.20634921,\n",
       "          -43.25396825,  -43.25396825],\n",
       "        [ -36.26984127,  -36.26984127,   38.33333333, ...,    3.41269841,\n",
       "          -41.82539683,  -41.82539683],\n",
       "        [-166.26984127, -166.26984127, -166.26984127, ..., -321.82539683,\n",
       "         -321.82539683, -321.82539683]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"1\"][\"eeg_data\"][\"rest1\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# assert eeg_data trials match marker trials\n",
    "\n",
    "trialMarkerLength = dcln.assertTrialsMarkersLength()\n",
    "trialMarkerLength.fit(data)\n",
    "print(trialMarkerLength.indices)\n",
    "clean_data = trialMarkerLength.transform(data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {}, '16': {'rest1': [0, 1], 'arith': [0, 1], 'rest2': [0, 1], 'auditory': [0, 1]}, '2': {}, '20': {'rest1': [], 'arith': [], 'rest2': [], 'auditory': [0]}, '23': {'rest1': [], 'arith': [0], 'rest2': [0], 'auditory': [0]}, '3': {'rest1': [0, 1], 'arith': [0, 1], 'rest2': [0, 1], 'auditory': [0, 1]}, '32': {'rest1': [0, 1, 2], 'arith': [0, 1, 2], 'rest2': [0, 1, 2], 'auditory': [0, 1, 2]}, '4': {'rest1': [0, 1], 'arith': [0, 1], 'rest2': [0, 1, 2], 'auditory': [0, 1, 2]}, '5': {'rest1': [0, 1], 'arith': [0, 1], 'rest2': [0, 1], 'auditory': [0, 1]}, '6': {'rest1': [], 'arith': [], 'rest2': [], 'auditory': [0]}, '8': {'rest1': [0, 1], 'arith': [0, 1], 'rest2': [0, 1], 'auditory': [0, 1]}, '9': {'rest1': [0, 1], 'arith': [0, 1], 'rest2': [0, 1], 'auditory': [0, 1]}}\n"
     ]
    }
   ],
   "source": [
    "# check for null eeg_data\n",
    "\n",
    "null_data_checker = dcln.nullIndicesTracer()\n",
    "null_data_checker.fit(clean_data)\n",
    "null_data_checker.indices[\"1\"] = {}\n",
    "null_data_checker.indices[\"2\"] = {}\n",
    "print(null_data_checker.indices)\n",
    "clean_data = null_data_checker.transform(clean_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerprocessing\n",
    "preprocess_method = [\n",
    "    [ppcn.channel_dropper, {\"index\": [19, 20, 21, 22, 23], \"axis\": 0}],\n",
    "    [ppcn.filter, {\"lfreq\": 75, \"hfreq\": 45, \"sfreq\": 200}],\n",
    "    [ppcn.filter, {\"lfreq\": 100, \"hfreq\": None, \"sfreq\": 200}],\n",
    "    # [ppcn.resampler,{'up':1,'down':1}],\n",
    "    [ppcn.baseline_corrector, {\"with_std\": False}],\n",
    "]\n",
    "\n",
    "preprocess_pipeline = ppcn.ppcn_pipeline(preprocess_method)\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n",
    "clean_data = ppcn.all_subjects_preprocessor(preprocess_pipeline, clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = ppcn.trials_as_subject_augmentation(\n",
    "    clean_data, data, null_data_checker.indices.keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auditory_data = pcn.xtract_phase_data(\"auditory\", clean_data)\n",
    "arithmetic_data = pcn.xtract_phase_data(\"arith\", clean_data)\n",
    "firstRest_data = pcn.xtract_phase_data(\"rest1\", clean_data)\n",
    "secondRest_data = pcn.xtract_phase_data(\"rest2\", clean_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auditory stimuli processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_data = audpcn.all_subjects_phase_auditory_epochs(auditory_data, 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_method = [\n",
    "    [audpcn.epoch_std, {}],\n",
    "    [audpcn.aud_stimuli_trial_average, {}],\n",
    "    # [ppcn.electrode_grouper,{'electrodes':electrodes,'target':['F','P','C','T','O']}]\n",
    "]\n",
    "aud_pcn_pipeline = audpcn.pipeline(aud_method)\n",
    "avg_aud = audpcn.all_subjects_processor(aud_pcn_pipeline, aud_data)\n",
    "\n",
    "mmn_pcn = audpcn.stimuli_mmn(\" \", 5)\n",
    "mmn_eeg = mmn_pcn.fit_transform(avg_aud)\n",
    "\n",
    "aud_method = [\n",
    "    [audpcn.epoch_MinMax, {\"range\": (-1, 1), \"axis\": 1}],\n",
    "]\n",
    "aud_pcn_pipeline = audpcn.pipeline(aud_method)\n",
    "mmn_eeg = audpcn.all_subjects_processor(aud_pcn_pipeline, mmn_eeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "trial_epoching.__init__() got an unexpected keyword argument 'dummy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Victor Momodu\\Documents\\Programming\\Machine Learning\\Code\\MMN_SZ\\notebooks\\preProcessingFeatures.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stft_feature_method\u001b[39m=\u001b[39m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [pcn\u001b[39m.\u001b[39mtrial_epoching,{\u001b[39m'\u001b[39m\u001b[39mdummy\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m}],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [pcn\u001b[39m.\u001b[39mstft,{\u001b[39m'\u001b[39m\u001b[39mfs\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m9\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msfreq\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m200\u001b[39m}],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [pcn\u001b[39m.\u001b[39mtrial_averaging,{\u001b[39m'\u001b[39m\u001b[39maxis\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdummy\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m}],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m stft_feature_pipeline\u001b[39m=\u001b[39mppcn\u001b[39m.\u001b[39;49mppcn_pipeline(stft_feature_method)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m firstRest_stft \u001b[39m=\u001b[39m pcn\u001b[39m.\u001b[39mall_subjects(stft_feature_pipeline,firstRest_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Victor%20Momodu/Documents/Programming/Machine%20Learning/Code/MMN_SZ/notebooks/preProcessingFeatures.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m arithmetic_stft \u001b[39m=\u001b[39m pcn\u001b[39m.\u001b[39mall_subjects(stft_feature_pipeline,arithmetic_data)\n",
      "File \u001b[1;32mc:\\Users\\Victor Momodu\\Documents\\Programming\\Machine Learning\\Code\\MMN_SZ\\notebooks\\generisAPI\\preprocessing.py:119\u001b[0m, in \u001b[0;36mppcn_pipeline.__init__\u001b[1;34m(self, processors)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mppc\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(processors)\n\u001b[0;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(processors)):\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mppc[i] \u001b[39m=\u001b[39m processors[i][\u001b[39m0\u001b[39;49m](\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprocessors[i][\u001b[39m1\u001b[39;49m])\n",
      "\u001b[1;31mTypeError\u001b[0m: trial_epoching.__init__() got an unexpected keyword argument 'dummy'"
     ]
    }
   ],
   "source": [
    "stft_feature_method = [\n",
    "    [pcn.trial_epoching, {\"dummy\": 0}],\n",
    "    [pcn.stft, {\"fs\": 9, \"sfreq\": 200}],\n",
    "    [pcn.trial_averaging, {\"axis\": 0, \"dummy\": 0}],\n",
    "    [ppcn.electrode_grouper, {\"electrodes\": electrodes, \"target\": \"F\"}],\n",
    "    [pcn.trial_averaging, {\"axis\": 0, \"dummy\": 0}],\n",
    "]\n",
    "\n",
    "stft_feature_pipeline = ppcn.ppcn_pipeline(stft_feature_method)\n",
    "\n",
    "firstRest_stft = pcn.all_subjects(stft_feature_pipeline, firstRest_data)\n",
    "arithmetic_stft = pcn.all_subjects(stft_feature_pipeline, arithmetic_data)\n",
    "secondRest_stft = pcn.all_subjects(stft_feature_pipeline, secondRest_data)\n",
    "auditory_stft = pcn.all_subjects(stft_feature_pipeline, auditory_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FuzzyEntropy Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzyEntropyMethod(electrode_choice):\n",
    "    fuzzy_entropy_method = [\n",
    "        [\n",
    "            ppcn.electrode_grouper,\n",
    "            {\"electrodes\": electrodes, \"target\": electrode_choice},\n",
    "        ],\n",
    "        [ppcn.dimension_augment_gaussian_noise, {\"minDim\": 6}],\n",
    "        [pcn.trial_epoching, {\"mode\": max}],\n",
    "        # [pcn.trial_averaging,{'axis':0,'dummy':0}],\n",
    "        [pcn.trial_averaging, {}],\n",
    "        [pcn.fuzzEnt, {\"m\": 2, \"mode\": \"hub\"}],\n",
    "        # [pcn.trial_averaging,{}],\n",
    "    ]\n",
    "\n",
    "    fuzzy_entropy_pipeline = ppcn.ppcn_pipeline(fuzzy_entropy_method)\n",
    "\n",
    "    return fuzzy_entropy_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frontal electrodes\n",
    "fuzzy_entropy_pipeline = fuzzyEntropyMethod(\"F\")\n",
    "\n",
    "frontal_entropies = {\n",
    "    \"rest1\": pcn.all_subjects(fuzzy_entropy_pipeline, firstRest_data),\n",
    "    \"arith\": pcn.all_subjects(fuzzy_entropy_pipeline, arithmetic_data),\n",
    "    \"rest2\": pcn.all_subjects(fuzzy_entropy_pipeline, secondRest_data),\n",
    "    # 'auditory':pcn.all_subjects(fuzzy_entropy_pipeline,auditory_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parietal electrodes,\n",
    "fuzzy_entropy_pipeline = fuzzyEntropyMethod(\"P\")\n",
    "\n",
    "parietal_entropies = {\n",
    "    \"rest1\": pcn.all_subjects(fuzzy_entropy_pipeline, firstRest_data),\n",
    "    \"arith\": pcn.all_subjects(fuzzy_entropy_pipeline, arithmetic_data),\n",
    "    \"rest2\": pcn.all_subjects(fuzzy_entropy_pipeline, secondRest_data),\n",
    "    # 'auditory':pcn.all_subjects(fuzzy_entropy_pipeline,auditory_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal electrodes\n",
    "fuzzy_entropy_pipeline = fuzzyEntropyMethod(\"T\")\n",
    "\n",
    "temporal_entropies = {\n",
    "    \"rest1\": pcn.all_subjects(fuzzy_entropy_pipeline, firstRest_data),\n",
    "    \"arith\": pcn.all_subjects(fuzzy_entropy_pipeline, arithmetic_data),\n",
    "    \"rest2\": pcn.all_subjects(fuzzy_entropy_pipeline, secondRest_data),\n",
    "    # 'auditory':pcn.all_subjects(fuzzy_entropy_pipeline,auditory_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occipital electrodes\n",
    "fuzzy_entropy_pipeline = fuzzyEntropyMethod(\"O\")\n",
    "\n",
    "occipital_entropies = {\n",
    "    \"rest1\": pcn.all_subjects(fuzzy_entropy_pipeline, firstRest_data),\n",
    "    \"arith\": pcn.all_subjects(fuzzy_entropy_pipeline, arithmetic_data),\n",
    "    \"rest2\": pcn.all_subjects(fuzzy_entropy_pipeline, secondRest_data),\n",
    "    # 'auditory':pcn.all_subjects(fuzzy_entropy_pipeline,auditory_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# central electrodes\n",
    "fuzzy_entropy_pipeline = fuzzyEntropyMethod(\"C\")\n",
    "\n",
    "central_entropies = {\n",
    "    \"rest1\": pcn.all_subjects(fuzzy_entropy_pipeline, firstRest_data),\n",
    "    \"arith\": pcn.all_subjects(fuzzy_entropy_pipeline, arithmetic_data),\n",
    "    \"rest2\": pcn.all_subjects(fuzzy_entropy_pipeline, secondRest_data),\n",
    "    # 'auditory':pcn.all_subjects(fuzzy_entropy_pipeline,auditory_data)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assr_method = [\n",
    "    [features.ASSR, {\"freq\": 20, \"dfreq\": 5, \"fs\": 200}],\n",
    "]\n",
    "assr_pipeline = ppcn.ppcn_pipeline(assr_method)\n",
    "\n",
    "firstRest_assr = pcn.all_subjects(assr_pipeline, firstRest_data)\n",
    "secondRest_assr = pcn.all_subjects(assr_pipeline, secondRest_data)\n",
    "auditory_assr = pcn.all_subjects(assr_pipeline, auditory_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMN Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Entropy Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### per subject and region distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noControls = list()\n",
    "noPatients = list()\n",
    "for s in data:\n",
    "    if s not in null_data_checker.indices:\n",
    "        if data[s][\"category\"] == \"Control\":\n",
    "            noControls.append(s)\n",
    "        elif data[s][\"category\"] == \"Patient\":\n",
    "            noPatients.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig, ax = plt.subplots(len(noControls), 5, figsize=(15, 16))\n",
    "fig.suptitle(\n",
    "    \"Barcharts of Fuzzy Entropy per control subject on rows with gaussan noise spatial compensation\"\n",
    ")\n",
    "sites = [\"F\", \"P\", \"C\", \"T\", \"O\"]\n",
    "for r, s in enumerate(noControls):\n",
    "    for c, ent in enumerate(\n",
    "        [\n",
    "            frontal_entropies,\n",
    "            parietal_entropies,\n",
    "            central_entropies,\n",
    "            temporal_entropies,\n",
    "            occipital_entropies,\n",
    "        ]\n",
    "    ):\n",
    "        plots.entropy_plot(ax[r, c], ent[\"rest1\"][s], 1)\n",
    "        plots.entropy_plot(ax[r, c], ent[\"arith\"][s], 2)\n",
    "        plots.entropy_plot(ax[r, c], ent[\"rest2\"][s], 3)\n",
    "        plots.entropy_plot(ax[r, c], ent[\"auditory\"][s], 4)\n",
    "        if c == 0:\n",
    "            ax[r, c].set_ylabel(\"Entropy[\" + s + \"]\")\n",
    "        else:\n",
    "            ax[r, c].set_ylabel(\" \")\n",
    "        if r == len(noControls) - 1:\n",
    "            ax[r, c].set_xticks([1, 2, 3, 4], [\"rest1\", \"arith\", \"rest2\", \"auditory\"])\n",
    "        else:\n",
    "            ax[r, c].set_xticks([], [])\n",
    "            if r == 0:\n",
    "                ax[r, c].set_title(sites[c])\n",
    "fig.tight_layout(pad=1.5)\n",
    "plt.savefig(\n",
    "    \"../data_analysis_results/FuzzEnt/Control/\" + \"all-fuzzyEntr.png\", format=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig, ax = plt.subplots(len(noPatients), 5, figsize=(15, 16))\n",
    "fig.suptitle(\n",
    "    \"Barcharts of Fuzzy Entropy per SZ(patient) subject on rows with gaussan noise spatial compensation\"\n",
    ")\n",
    "sites = [\"F\", \"P\", \"C\", \"T\", \"O\"]\n",
    "for r, s in enumerate(noPatients):\n",
    "    for c, ent in enumerate(\n",
    "        [\n",
    "            frontal_entropies,\n",
    "            parietal_entropies,\n",
    "            central_entropies,\n",
    "            temporal_entropies,\n",
    "            occipital_entropies,\n",
    "        ]\n",
    "    ):\n",
    "        plots.entropy_plot(ax[r, c], ent[\"rest1\"][s], 1)\n",
    "        plots.entropy_plot(ax[r, c], ent[\"arith\"][s], 2)\n",
    "        plots.entropy_plot(ax[r, c], ent[\"rest2\"][s], 3)\n",
    "        plots.entropy_plot(ax[r, c], ent[\"auditory\"][s], 4)\n",
    "        if c == 0:\n",
    "            ax[r, c].set_ylabel(\"Entropy[\" + s + \"]\")\n",
    "        else:\n",
    "            ax[r, c].set_ylabel(\" \")\n",
    "        if r == len(noPatients) - 1:\n",
    "            ax[r, c].set_xticks([1, 2, 3, 4], [\"rest1\", \"arith\", \"rest2\", \"auditory\"])\n",
    "        else:\n",
    "            ax[r, c].set_xticks([], [])\n",
    "            if r == 0:\n",
    "                ax[r, c].set_title(sites[c])\n",
    "fig.tight_layout(pad=1.5)\n",
    "plt.savefig(\n",
    "    \"../data_analysis_results/FuzzEnt/Patient/\" + \"all-fuzzyEntr.png\", format=\"png\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def all_region_entropies(region_entropies):\n",
    "    control = {\n",
    "        \"rest1\": np.empty(1),\n",
    "        \"arith\": np.empty(1),\n",
    "        \"rest2\": np.empty(1),\n",
    "        \"auditory\": np.empty(1),\n",
    "    }\n",
    "    patient = copy.deepcopy(control)\n",
    "\n",
    "    for s in noControls:\n",
    "        for p in control.keys():\n",
    "            control[p] = np.concatenate((control[p], region_entropies[p][s]), axis=0)\n",
    "\n",
    "    for s in noPatients:\n",
    "        for p in patient.keys():\n",
    "            patient[p] = np.concatenate((patient[p], region_entropies[p][s]), axis=0)\n",
    "\n",
    "    return control, patient\n",
    "\n",
    "\n",
    "def region_entropies_kde(region_entropies, ax):\n",
    "    control, patient = all_region_entropies(region_entropies)\n",
    "    x = [\n",
    "        control[\"rest1\"],\n",
    "        control[\"arith\"],\n",
    "        control[\"rest2\"],\n",
    "        control[\"auditory\"],\n",
    "        patient[\"rest1\"],\n",
    "        patient[\"arith\"],\n",
    "        patient[\"rest2\"],\n",
    "        patient[\"auditory\"],\n",
    "    ]\n",
    "    x = pd.DataFrame(\n",
    "        x,\n",
    "        index=[\n",
    "            \"control_rest1\",\n",
    "            \"control_arith\",\n",
    "            \"control_rest2\",\n",
    "            \"control_auditory\",\n",
    "            \"patient_rest1\",\n",
    "            \"patient_arith\",\n",
    "            \"patient_rest2\",\n",
    "            \"patient_auditory\",\n",
    "        ],\n",
    "    ).T\n",
    "    # x = x.fillna(0)\n",
    "    # print(x)\n",
    "\n",
    "    x.plot(\n",
    "        kind=\"kde\",\n",
    "        subplots=[\n",
    "            (\"control_rest1\", \"patient_rest1\"),\n",
    "            (\"control_arith\", \"patient_arith\"),\n",
    "            (\"control_rest2\", \"patient_rest2\"),\n",
    "            (\"control_auditory\", \"patient_auditory\"),\n",
    "        ],\n",
    "        sharex=False,\n",
    "        layout=(1, 4),\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig, ax = plt.subplots(5, 4, figsize=(12, 10))\n",
    "fig.suptitle(\"Fuzzy Entropy Distributions\")\n",
    "region_entropies_kde(frontal_entropies, ax[0, :])\n",
    "region_entropies_kde(parietal_entropies, ax[1, :])\n",
    "region_entropies_kde(central_entropies, ax[2, :])\n",
    "region_entropies_kde(temporal_entropies, ax[3, :])\n",
    "region_entropies_kde(occipital_entropies, ax[4, :])\n",
    "fig.tight_layout()\n",
    "for c in range(1, 4):\n",
    "    for r in range(5):\n",
    "        ax[r, c].set_ylabel(\"\")\n",
    "for r in range(5):\n",
    "    temp = [\"F\", \"P\", \"C\", \"T\", \"O\"]\n",
    "    ax[r, 0].set_ylabel(\" Density\" + \"(\" + temp[r] + \")\")\n",
    "del temp\n",
    "plt.savefig(\n",
    "    \"../data_analysis_results/FuzzEnt/corticalRegions_DAQphase_distributions.png\",\n",
    "    format=\"png\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features per subject Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzyEntropySubjectCombiner(entropies):\n",
    "    res_control = dict().fromkeys(entropies)\n",
    "    res_patient = dict().fromkeys(entropies)\n",
    "    for phase in entropies:\n",
    "        mean_val_patient = 0\n",
    "        mean_val_control = 0\n",
    "        for i, s in enumerate(entropies[phase]):\n",
    "            if s not in null_data_checker.indices:\n",
    "                if data[s][\"category\"] == \"Control\":\n",
    "                    mean_val_control += np.array(entropies[phase][s]).mean()\n",
    "                else:\n",
    "                    mean_val_patient += np.array(entropies[phase][s]).mean()\n",
    "        res_control[phase] = mean_val_control / 12\n",
    "        res_patient[phase] = mean_val_patient / 10\n",
    "    return res_control, res_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontalEntropies = fuzzyEntropySubjectCombiner(frontal_entropies)\n",
    "parietalEntropies = fuzzyEntropySubjectCombiner(parietal_entropies)\n",
    "temporalEntropies = fuzzyEntropySubjectCombiner(temporal_entropies)\n",
    "centralEntropies = fuzzyEntropySubjectCombiner(central_entropies)\n",
    "occipitalEntropies = fuzzyEntropySubjectCombiner(occipital_entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(19, 4))\n",
    "\n",
    "for i, ent in enumerate(\n",
    "    [\n",
    "        frontalEntropies,\n",
    "        parietalEntropies,\n",
    "        temporalEntropies,\n",
    "        centralEntropies,\n",
    "        occipitalEntropies,\n",
    "    ]\n",
    "):\n",
    "    y1 = [ent[0][k] for k in ent[0]]\n",
    "    y2 = [ent[1][k] for k in ent[1]]\n",
    "    ax[i].plot(y1, \"--\", label=\"Control\")\n",
    "    ax[i].plot(y2, \"--\", label=\"Patient\")\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"Fuzzy Entropy\")\n",
    "        ax[i].legend()\n",
    "    ax[i].set_xticks([0, 1, 2, 3], [\"1st Rest\", \"Arithemtic\", \"2nd Rest\", \"Auditory\"])\n",
    "ax[0].set_title(\"Frontal Electrodes\")\n",
    "ax[1].set_title(\"Parietal  Electrodes\")\n",
    "ax[2].set_title(\"Temporal Electrodes\")\n",
    "ax[3].set_title(\"Central Electrod/es\")\n",
    "ax[4].set_title(\"Occipital Electrodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmnCombine(mmn):\n",
    "    res_control = dict().fromkeys([\" \", \"1000Hz\", \"3000Hz\"])\n",
    "    res_patient = dict().fromkeys([\" \", \"1000Hz\", \"3000Hz\"])\n",
    "\n",
    "    for i, s in enumerate(mmn):\n",
    "        tdevControl, tdevPatient = np.empty((4, 20)), np.empty((4, 20))\n",
    "        onekControl, onekPatient = np.empty((4, 20)), np.empty((4, 20))\n",
    "        threekControl, threekPatient = np.empty((4, 20)), np.empty((4, 20))\n",
    "        if s not in null_data_checker.indices:\n",
    "            if data[s][\"category\"] == \"Control\":\n",
    "                tdevControl += mmn[s][\" \"]\n",
    "                onekControl += mmn[s][\"1000Hz\"]\n",
    "                threekControl += mmn[s][\"3000Hz\"]\n",
    "            else:\n",
    "                tdevPatient += mmn[s][\" \"]\n",
    "                onekPatient += mmn[s][\"1000Hz\"]\n",
    "                threekPatient += mmn[s][\"3000Hz\"]\n",
    "    res_control[\" \"] = tdevControl / 12\n",
    "    res_control[\"1000Hz\"] = onekControl / 12\n",
    "    res_control[\"3000Hz\"] = threekControl / 12\n",
    "    res_patient[\" \"] = tdevPatient / 10\n",
    "    res_patient[\"1000Hz\"] = onekPatient / 10\n",
    "    res_patient[\"3000Hz\"] = threekPatient / 10\n",
    "    return res_control, res_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmns = mmnCombine(avg_aud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, figsize=(16, 6))\n",
    "xi = list(range(0, 20, 4))\n",
    "x = (np.array(xi) / 200).tolist()\n",
    "ch = [\"T3\", \"T4\", \"T5\", \"T6\"]\n",
    "for r in range(3):\n",
    "    ks = [\" \", \"1000Hz\", \"3000Hz\"]\n",
    "    for c in range(4):\n",
    "        ax[r, c].plot(mmns[0][ks[r]][c, :], label=\"Control\")\n",
    "        ax[r, c].plot(mmns[1][ks[r]][c, :], label=\"Patient\")\n",
    "        ax[r, c].set_xticks([], [])\n",
    "ax[0, 0].legend()\n",
    "ax[0, 0].set_title(\"T3\")\n",
    "ax[0, 1].set_title(\"T4\")\n",
    "ax[0, 2].set_title(\"T5\")\n",
    "ax[0, 3].set_title(\"T6\")\n",
    "ax[2, 0].set_xticks(xi, x)\n",
    "ax[2, 1].set_xticks(xi, x)\n",
    "ax[2, 2].set_xticks(xi, x)\n",
    "ax[2, 3].set_xticks(xi, x)\n",
    "ax[0, 0].set_ylabel(\" (uV)\")\n",
    "ax[1, 0].set_ylabel(\"1000Hz (uV)\")\n",
    "ax[2, 0].set_ylabel(\"3000Hz (uV)\")\n",
    "ax[2, 0].set_xlabel(\"Time(s)\")\n",
    "ax[2, 1].set_xlabel(\"Time(s)\")\n",
    "ax[2, 2].set_xlabel(\"Time(s)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_features_list = [\n",
    "    \"frontalEntropy(rest1)\",\n",
    "    \"frontalEntropy(arith)\",\n",
    "    \"frontalEntropy(rest2)\",\n",
    "    \"parietalEntropy(rest1)\",\n",
    "    \"parietalEntropy(arith)\",\n",
    "    \"parietalEntropy(rest2)\",\n",
    "    \"centralEntropy(rest1)\",\n",
    "    \"centralEntropy(arith)\",\n",
    "    \"centralEntropy(rest2)\",\n",
    "    \"temporalEntropy(rest1)\",\n",
    "    \"temporalEntropy(arith)\",\n",
    "    \"temporalEntropy(rest2)\",\n",
    "    \"occipitalEntropy(rest1)\",\n",
    "    \"occipitalEntropy(arith)\",\n",
    "    \"occipitalEntropy(rest2)\",\n",
    "    \"category\",\n",
    "    # 'rest1_assr_amplitude','rest1_assr_phase',\n",
    "    # 'rest2_assr_amplitude','rest1_assr_phase',\n",
    "    # 'aud_assr_amplitude','aud_assr_phase'\n",
    "]\n",
    "\n",
    "entropy_features = dict().fromkeys(entropy_features_list)\n",
    "\n",
    "existing_entropies = [\n",
    "    frontal_entropies,\n",
    "    parietal_entropies,\n",
    "    central_entropies,\n",
    "    temporal_entropies,\n",
    "    occipital_entropies,\n",
    "]\n",
    "their_names = [\n",
    "    \"frontalEntropy\",\n",
    "    \"parietalEntropy\",\n",
    "    \"centralEntropy\",\n",
    "    \"temporalEntropy\",\n",
    "    \"occipitalEntropy\",\n",
    "]\n",
    "for k in entropy_features:\n",
    "    entropy_features[k] = dict()\n",
    "for s in clean_data:\n",
    "    if s not in null_data_checker.indices:\n",
    "        # features['MMN_1KHz'][s] = mmn_eeg[s]['1000Hz']\n",
    "        # features['MMN_3KHz'][s] = mmn_eeg[s]['3000Hz']\n",
    "        # features['rest1_assr_amplitude'][s] = firstRest_assr[s][0]\n",
    "        # features['rest1_assr_phase'][s] = firstRest_assr[s][1]\n",
    "        # features['rest2_assr_amplitude'][s] = secondRest_assr[s][0]\n",
    "        # features['rest2_assr_phase'][s] = secondRest_assr[s][1]\n",
    "        # features['aud_assr_amplitude'][s] = auditory_assr[s][0]\n",
    "        # features['aud_assr_phase'][s] = auditory_assr[s][1]\n",
    "        for ent, ent_name in zip(existing_entropies, their_names):\n",
    "            for k in [\"rest1\", \"arith\", \"rest2\"]:\n",
    "                try:\n",
    "                    entropy_features[ent_name + \"(\" + k + \")\"][s] = np.mean(ent[k][s])\n",
    "                except ValueError:\n",
    "                    entropy_features[ent_name + \"(\" + k + \")\"][s] = 0\n",
    "        entropy_features[\"category\"][s] = clean_data[s][\"category\"]\n",
    "\n",
    "entropy_features = pd.DataFrame(entropy_features)\n",
    "# entropy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmn_eeg_timeSeries = {\"mmn_eeg\": mmn_eeg, \"cateory\": entropy_features[\"category\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assr_amplitude_phase_features = {\n",
    "    \"1stRest_assr\": firstRest_assr,\n",
    "    \"2ndRest_assr\": secondRest_assr,\n",
    "    \"aud_assr\": auditory_assr,\n",
    "    \"category\": entropy_features[\"category\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(entropy_features,'../features/fuzzyEntropy.sav')\n",
    "# joblib.dump(mmn_eeg_timeSeries,'../features/mmnEEGtimeSeries.sav')\n",
    "# joblib.dump(assr_amplitude_phase_features,'../features/assr.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assr_amplitude_phase_features[\"1stRest_assr\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroBCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e90a6d84881e26bdcd429ff578d89ac8215c640b331c30db911ced7e0cf75981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
